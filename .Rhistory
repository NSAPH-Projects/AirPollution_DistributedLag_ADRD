plot(s, "slice", val = 15)
plot(s, "cumulative")
(s <- summary(m, cenval = 0))#, cenval = splits[3]))
plot(s)
plot(s, "slice", time = 1)
plot(s, "slice", val = 15)
plot(s, "cumulative")
(s <- summary(m, cenval = 5))#, cenval = splits[3]))
plot(s)
plot(s, "slice", time = 1)
plot(s, "slice", val = 15)
plot(s, "cumulative")
rm(list=ls())
gc()
library(data.table)
library(fst)
dir_denominator <- "/nfs/home/D/dam9096/shared_space/ci3_health_data/medicare/mortality/1999_2016/wu/cache_data/merged_by_year_v2/"
f <- list.files(dir_denominator, pattern = "\\.fst", full.names = TRUE)
myvars <- c("qid", "year", "zip", "hmo_mo", "age")
myvars <- c("qid", "year", "age")
f
dt09_10 <- rbindlist(list(read_fst(f[11], as.data.table = TRUE),
read_fst(f[12], as.data.table = TRUE)))
# ############################################################################ #
#' Project: ADRD Distributed Lag Analysis
#' Code: region distributed lag analysis
#' Inputs: merged denominator and exposure data
#' Outputs:
#' Author: Daniel Mork
#' Last updated: Mar 09, 2022
#' Memory to run: 32 GB
# ############################################################################ #
rm(list = ls())
gc()
##### 0. Setup #####
region <- "NE"
AD_ADRD <- "ADRD" # AD or ADRD
code_type <- "any" # primary or any
library(data.table)
library(fst)
library(NSAPHutils)
options(stringsAsFactors = FALSE)
setDTthreads(threads = 16)
dir_data <- "/nfs/home/D/dam9096/shared_space/ci3_analysis/dmork/Data/DLM_ADRD/"
##### 1. Load relevant data #####
qid_dat <- read_fst(paste0(dir_data, "analysis/region", region, "_", AD_ADRD, "_",
code_type, "_qid.fst"), as.data.table = TRUE)
pm25_dat <- read_fst(paste0(dir_data, "analysis/region", region, "_", AD_ADRD, "_",
code_type, "_pm25.fst"), as.data.table = TRUE)
colnames(pm25_dat)
##### 2. Restrict to complete follow-up 2010 through 2016, no deaths #####
pm25_dat <- as.matrix(pm25_dat[, -c(1:3, 20)])[, 16:1] # reorder exposures, remove keys and lag0
idx <- which(rowSums(is.na(pm25_dat[, 1:10])) == 0 & # no missing exposures
rowSums(pm25_dat[, 1:10] == 0) == 0 & # no zero exposures
qid_dat$entry == 2000 & # follow up from 2000
qid_dat$year > 2009) # year 2010 and later for 10 lag years exposures
idx <- which(rowSums(is.na(pm25_dat[, 1:10])) == 0 & # no missing exposures
rowSums(pm25_dat[, 1:10] == 0) == 0 & # no zero exposures
qid_dat$entry == 2000 & # follow up from 2000
qid_dat$year > 2009 & # year 2010 and later for 10 lag years exposures
qid_dat$correct_ages) # no age inconsistencies
idx <- which(rowSums(is.na(pm25_dat[, 1:10])) == 0 & # no missing exposures
rowSums(pm25_dat[, 1:10] == 0) == 0 & # no zero exposures
qid_dat$entry == 2000 & # follow up from 2000
qid_dat$year > 2009) # year 2010 and later for 10 lag years exposures
qid_dat <- qid_dat[idx]
pm25_dat <- pm25_dat[idx,]
##### Data fixes #####
qid_dat[, age_corrected := entry_age + year - entry]
qid_dat[, PIR := medianhousevalue/medhouseholdincome]
# clear missing data, infinite PIR
idx2 <- which(complete.cases(qid_dat[,.(year, age_corrected, dual, race, sexM,
education, poverty, medianhousevalue,
medhouseholdincome, pct_blk, hispanic,
popdensity, pct_owner_occ, PIR)]) &
!is.infinite(qid_dat$PIR))
qid_dat <- qid_dat[idx2]
pm25_dat <- pm25_dat[idx2,]
##### Remove QID after missing year of data #####
idx3 <- which(qid_dat$year == 2010)
qid_rm <- qid_dat[idx3, qid]
for (yr in 2011:2016) {
idx3 <- c(idx3, which(qid_dat$year == yr & qid_dat$qid %in% qid_rm))
qid_rm <- qid_dat[idx3][year == yr, qid]
}
qid_dat <- qid_dat[idx3]
pm25_dat <- pm25_dat[idx3,]
setkey(qid_dat, year, zip, qid)
rm(idx, idx2, idx3, qid_rm)
##### Summary stats #####
qid_dat[, .N]
qid_dat[, .N, by = year]
qid_dat[, uniqueN(qid)]
qid_dat[, uniqueN(qid), by = year]
##### Summary stats #####
qid_dat[, .N]
qid_dat[, sum(first_hosp)]
qid_dat[, .(sum(first_hosp), sum(dead)), by = year]
qid_dat[, sum(first_hosp)/uniqueN(qid)]
qid_dat[, sum(dead)/uniqueN(qid)]
qid_dat[, .(sum(first_hosp)/uniqueN(qid), sum(dead)/uniqueN(qid)), by = year]
##### 3. DLM analysis - TDLM #####
library(dlmtree)
(splits <- quantile(pm25_dat[, 1:10], c(0.05, 1:9/10, 0.95)))
sd(pm25_dat[, 1:10])
hist(pm25_dat[,1:10])
colnames(pm25_dat)
##### 5. DLM analysis - GAM #####
library(dlnm)
library(mgcv)
cb <- crossbasis(pm25_dat[, 1:10], c(1, 10),
argvar = list(fun = "lin"),
arglag = list(fun = "cr"))
cb_pen <- cbPen(cb)
m2 <- bam(first_hosp ~ factor(year) - 1 +
cb +
age_corrected + I(age_corrected^2) +
factor(dual) + factor(race) + factor(sexM) +
education + poverty + PIR +
pct_blk + hispanic + popdensity + pct_owner_occ,
data = qid_dat,
paraPen = list(cb = cb_pen),
family = binomial,
nthreads = 16,
control = gam.control(trace = TRUE))
cp <- crosspred(cb, m2, at = 5:15, bylag = 0.2)
plot(cp, "slices", var = 6)
plot(cp, "overall")
cp <- crosspred(cb, m2, cen = 5, at = 5:15, bylag = 0.2)
plot(cp, "slices", var = 6)
plot(cp, "overall")
(splits <- quantile(pm25_dat[, 1:10], 1:19/20))
m <- tdlnm(first_hosp ~ factor(year) - 1 +
age_corrected + I(age_corrected^2) +
factor(dual) + factor(race) + factor(sexM) +
education + poverty + PIR +
pct_blk + hispanic + popdensity + pct_owner_occ,
data = qid_dat,
exposure.data = pm25_dat[, 1:10],
exposure.splits = splits,
exposure.se = sd(pm25_dat[, 1:10]) / 2,
family = "logit",
n.trees = 10, n.burn = 2000, n.iter = 5000, n.thin = 5,
max.threads = 8)
save(m, file = paste0(dir_data, "analysis/tdlnm_region", region, "_", AD_ADRD, "_",
code_type, "_pm25.rda"))
(s <- summary(m, cenval = m$Xsplits[1]))
plot(s)
plot(s,"slice",val=20)
plot(s,"slice",val=10)
plot(s,"slice",val=5)
plot(s,"slice",val=8)
plot(s,"slice",val=12)
plot(s,"slice",val=14)
plot(s,"slice",val=16)
plot(s,"slice",time=2)
plot(s,"slice",time=4)
plot(s,"slice",time=6)
plot(s,"slice",time=8)
plot(s,"slice",time=10)
plot(s,"cumulative")
splits
(s <- summary(m, cenval = 10))#m$Xsplits[1]))
plot(s)
plot(s,"slice",val=20)
# ############################################################################ #
#' Project: ADRD Distributed Lag Analysis
#' Code: continental US analysis data creation
#' Inputs: denominator data (2000-2016)
#' Outputs: cleaned yearly qid enrollment and individual data
#' Author: Daniel Mork
#' Last updated: Mar 09, 2022
#' Memory to run: 64 GB
# ############################################################################ #
rm(list = ls())
gc()
##### 0. Setup #####
# 4 regions based on census?
NE <- c("NY", "MA", "PA", "RI", "NH", "ME", "VT", "CT", "NJ")
S <- c("DC", "VA", "NC", "WV", "KY", "SC", "GA", "FL", "AL", "TN", "MS",
"AR", "MD", "DE", "OK", "TX", "LA")
MW <- c("OH", "IN", "MI", "IA", "MO", "WI", "MN", "SD", "ND", "IL", "KS", "NE")
W <- c("MT", "CO", "WY", "ID", "UT", "NV", "CA", "OR", "WA", "AZ", "NM")
AD_ADRD <- "ADRD" # AD or ADRD
code_type <- "any" # primary, secondary, or any
library(data.table)
library(fst)
library(NSAPHutils)
options(stringsAsFactors = FALSE)
setDTthreads(threads = 16)
dir_data <- "/nfs/home/D/dam9096/shared_space/ci3_analysis/dmork/Data/DLM_ADRD/"
# year/zip confounders
yr_zip_confounders <- read_fst(paste0(dir_data, "denom/year_zip_confounders.fst"),
as.data.table = TRUE)
yr_zip_confounders[, region := ifelse(statecode %in% NE, "NE",
ifelse(statecode %in% S, "S",
ifelse(statecode %in% MW, "MW",
ifelse(statecode %in% W, "W", "Other"))))]
yr_zip_confounders[,.N,by=region]
setkey(yr_zip_confounders, year, zip)
valid_zips <- sort(unique(yr_zip_confounders[statecode != "Other", zip]))
length(valid_zips)
# hospitalization data
hosp_dat <- read_fst(paste0(dir_data,
"hospitalization/First_hosp_", AD_ADRD, "_", code_type, ".fst"),
as.data.table = TRUE)
hosp_dat[, first_hosp := TRUE]
pre2009_qid <- hosp_dat[year < 2009, QID]
hosp_dat <- hosp_dat[year >= 2009]
# FFS beneficiary enrollment history
qid_entry_exit <- read_fst(paste0(dir_data, "denom/qid_entry_exit.fst"),
as.data.table = TRUE)
qid_entry_exit <- qid_entry_exit[exit >= 2009 & # find all QIDs with exit after 2009
entry == 2000 & # entry 2000
!(qid %in% pre2009_qid) & # eliminate prior ADRD hosp
cont_enroll == TRUE] # restrict to continuously enrolled
setkey(qid_entry_exit, qid)
# FFS beneficiary yearly data
qid_dat <- data.table()
for (yr in 2009:2016) {
cat("\nReading year", yr)
dt <- read_fst(paste0(dir_data, "denom/qid_data_", yr, ".fst"),
as.data.table = TRUE)
dt <- dt[zip %in% valid_zips & # restrict to continental US zipcodes
qid %in% qid_entry_exit$qid & # restrict to exit after 2009, continuous enrollment, no prior ADRD hosp
!(qid %in% hosp_dat[year < yr, QID])] # eliminate ADRD hosp prior to current year
cat(" -", dt[,.N], "records")
qid_dat <- rbindlist(list(qid_dat, dt))
rm(dt)
}
setkey(qid_dat, year, zip, qid)
##### 2. Merge data sources #####
qid_dat <- merge(qid_dat, hosp_dat[, .(QID, year, first_hosp)],
by.x = c("year", "qid"), by.y = c("year", "QID"),
all.x = TRUE)
qid_dat[is.na(first_hosp), first_hosp := FALSE]
qid_dat <- merge(qid_dat, yr_zip_confounders, by = c("year", "zip"), all.x = TRUE)
qid_dat <- merge(qid_dat, qid_entry_exit, by = "qid", all.x = TRUE)
setkey(qid_dat, year, zip, qid)
write_fst(qid_dat, paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
code_type, "_qid.fst"))
rm(hosp_dat, yr_zip_confounders, qid_entry_exit, pre2009_qid); gc()
##### 3. Create corresponding exposure data #####
exposures <- c("pm25", "no2", "ozone", "tmmx", "rmax", "pr") # from pm25, no2, ozone, tmmx, rmax, pr
for (e in exposures) {
cat("\nCreating exposure data:", e, "...")
qid_yr_exp <- read_fst(paste0(dir_data, "qid_yr_exposures/qid_yr_", e, ".fst"),
as.data.table = TRUE)
qid_yr_exp <- qid_yr_exp[qid %in% qid_dat$qid]
setkey(qid_yr_exp, qid)
exp_dat <- rbindlist(lapply(2016:2009, function(y) {
dt <- merge(qid_dat[year == y, .(qid, year, zip)],
qid_yr_exp[, c("qid", as.character(2000:y)), with = FALSE],
by = "qid", all.x = TRUE)
setnames(dt, c("qid", "year", "zip", paste0("lag", (y - 2000):0)))
dt
}), use.names = TRUE, fill = TRUE)
setkey(exp_dat, year, zip, qid)
write_fst(exp_dat, paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
code_type, "_", e, ".fst"))
rm(exp_dat)
cat(" complete.")
}
# ############################################################################ #
#' Project: ADRD Distributed Lag Analysis
#' Code: continental US distributed lag analysis
#' Inputs: merged denominator and exposure data
#' Outputs:
#' Author: Daniel Mork
#' Last updated: Mar 09, 2022
#' Memory to run: 96 GB
# ############################################################################ #
rm(list = ls())
gc()
##### 0. Setup #####
AD_ADRD <- "ADRD" # AD or ADRD
code_type <- "any" # primary or any
library(data.table)
library(fst)
library(NSAPHutils)
options(stringsAsFactors = FALSE)
setDTthreads(threads = 16)
dir_data <- "/nfs/home/D/dam9096/shared_space/ci3_analysis/dmork/Data/DLM_ADRD/"
##### 1. Load relevant data #####
qid_dat <- read_fst(paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
code_type, "_qid.fst"), as.data.table = TRUE)
pm25_dat <- read_fst(paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
code_type, "_pm25.fst"), as.data.table = TRUE)
# no2_dat <- read_fst(paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
#                            code_type, "_no2.fst"), as.data.table = TRUE)
# ozone_dat <- read_fst(paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
#                              code_type, "_ozone.fst"), as.data.table = TRUE)
# tmmx_dat <- read_fst(paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
#                              code_type, "_tmmx.fst"), as.data.table = TRUE)
# rmax_dat <- read_fst(paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
#                              code_type, "_rmax.fst"), as.data.table = TRUE)
# pr_dat <- read_fst(paste0(dir_data, "analysis/contUS_", AD_ADRD, "_",
#                              code_type, "_pr.fst"), as.data.table = TRUE)
pm25_dat <- as.matrix(pm25_dat[, -c(1:3, 20)])[, 16:1] # reorder exposures, remove keys and lag0
##### 2. Restrict to complete follow-up 2010 through 2016, no deaths #####
idx <- which(rowSums(is.na(pm25_dat[, 1:10])) == 0 & # no missing exposures lags 1-10
# rowSums(is.na(no2_dat[, 1:10])) == 0 &
# rowSums(is.na(ozone_dat[, 1:10])) == 0 &
# rowSums(is.na(tmmx_dat[, 1:10])) == 0 &
# rowSums(is.na(rmax_dat[, 1:10])) == 0 &
# rowSums(is.na(pr_dat[, 1:10])) == 0 &
qid_dat$entry == 2000 & # follow up from 2000
qid_dat$year > 2009) # year 2010 and later for 10 lag years exposures
qid_dat <- qid_dat[idx]
pm25_dat <- pm25_dat[idx,]
##### Data fixes #####
qid_dat[, age_corrected := entry_age + year - entry]
qid_dat[, PIR := medianhousevalue/medhouseholdincome]
# clear missing data, infinite PIR
idx2 <- which(complete.cases(qid_dat[,.(year, age_corrected, dual, race, sexM,
region,
education, poverty, pct_blk, hispanic,
popdensity, pct_owner_occ, PIR)]) &
!is.infinite(qid_dat$PIR))
qid_dat <- qid_dat[idx2]
pm25_dat <- pm25_dat[idx2,]
##### Remove QID after missing year of data #####
idx3 <- which(qid_dat$year == 2010)
qid_rm <- qid_dat[idx3, qid]
for (yr in 2011:2016) {
idx3 <- c(idx3, which(qid_dat$year == yr & qid_dat$qid %in% qid_rm))
qid_rm <- qid_dat[idx3][year == yr, qid]
}
qid_dat <- qid_dat[idx3]
pm25_dat <- pm25_dat[idx3,]
# no2_dat <- no2_dat[idx3,]
# ozone_dat <- ozone_dat[idx3,]
# tmmx_dat <- tmmx_dat[idx3,]
# rmax_dat <- rmax_dat[idx3,]
# pr_dat <- pr_dat[idx3,]
setkey(qid_dat, year, zip, qid)
rm(idx, idx2, idx3, qid_rm)
##### 5. DLM analysis - GAM #####
library(dlnm)
library(mgcv)
cb <- crossbasis(pm25_dat[, 1:10], c(1, 10),
argvar = list(fun = "lin"),
arglag = list(fun = "ps", df = 5))
cb_pen <- cbPen(cb)
m2 <- bam(first_hosp ~ factor(year) - 1 +
factor(region) +
cb +
age_corrected + I(age_corrected^2) +
factor(dual) + factor(race) + factor(sexM) +
education + poverty + PIR +
pct_blk + hispanic + popdensity + pct_owner_occ,
data = qid_dat,
#subset = sample(qid_dat[,.N], 100000),#which(qid_dat$year == 2016),
paraPen = list(cb = cb_pen),
family = binomial,
nthreads = 16,
control = gam.control(trace = TRUE))
summary(m2)
cp <- crosspred(cb, m2, cen = 5, at = 2:25, bylag = 0.2)
plot(cp, "slices", var = 10)
plot(cp, "overall")
cb <- crossbasis(pm25_dat[, 1:10], c(1, 10),
argvar = list(fun = "lin"),
arglag = list(fun = "cr", df = 5))
cb_pen <- cbPen(cb)
m2 <- bam(first_hosp ~ factor(year) - 1 +
factor(region) +
cb +
age_corrected + I(age_corrected^2) +
factor(dual) + factor(race) + factor(sexM) +
education + poverty + PIR +
pct_blk + hispanic + popdensity + pct_owner_occ,
data = qid_dat,
paraPen = list(cb = cb_pen),
family = binomial,
nthreads = 16,
control = gam.control(trace = TRUE))
summary(m2)
cp <- crosspred(cb, m2, cen = 5, at = 2:25, bylag = 0.2)
plot(cp, "slices", var = 10)
plot(cp, "overall")
save(cp, file = paste0(dir_data, "analysis/gamcr_contUS_", AD_ADRD, "_",
code_type, ".rda"))
# ############################################################################ #
#' Project: ADRD Distributed Lag Analysis
#' Code: single state distributed lag analysis
#' Inputs: merged denominator and exposure data
#' Outputs:
#' Author: Daniel Mork
#' Last updated: Mar 09, 2022
#' Memory to run: 32 GB
# ############################################################################ #
rm(list = ls())
gc()
##### 0. Setup #####
state <- "MA"
AD_ADRD <- "ADRD" # AD or ADRD
code_type <- "any" # primary, secondary, or any
library(data.table)
library(fst)
library(NSAPHutils)
options(stringsAsFactors = FALSE)
setDTthreads(threads = 5)
dir_data <- "/nfs/home/D/dam9096/shared_space/ci3_analysis/dmork/Data/DLM_ADRD/"
##### 1. Load relevant data #####
qid_dat <- read_fst(paste0(dir_data, "analysis/state", state, "_", AD_ADRD, "_",
code_type, "_qid.fst"), as.data.table = TRUE)
pm25_dat <- read_fst(paste0(dir_data, "analysis/state", state, "_", AD_ADRD, "_",
code_type, "_pm25.fst"), as.data.table = TRUE)
no2_dat <- read_fst(paste0(dir_data, "analysis/state", state, "_", AD_ADRD, "_",
code_type, "_no2.fst"), as.data.table = TRUE)
ozone_dat <- read_fst(paste0(dir_data, "analysis/state", state, "_", AD_ADRD, "_",
code_type, "_ozone.fst"), as.data.table = TRUE)
tmmx_dat <- read_fst(paste0(dir_data, "analysis/state", state, "_", AD_ADRD, "_",
code_type, "_tmmx.fst"), as.data.table = TRUE)
rmax_dat <- read_fst(paste0(dir_data, "analysis/state", state, "_", AD_ADRD, "_",
code_type, "_rmax.fst"), as.data.table = TRUE)
pr_dat <- read_fst(paste0(dir_data, "analysis/state", state, "_", AD_ADRD, "_",
code_type, "_pr.fst"), as.data.table = TRUE)
pm25_dat <- as.matrix(pm25_dat[, -c(1:3, 20)])[, 16:1] # reorder exposures, remove keys
no2_dat <- as.matrix(no2_dat[, -c(1:3, 20)])[, 16:1] # reorder exposures, remove keys
ozone_dat <- as.matrix(ozone_dat[, -c(1:3, 20)])[, 16:1] # reorder exposures, remove keys
tmmx_dat <- as.matrix(tmmx_dat[, -c(1:3, 20)])[, 16:1] # reorder exposures, remove keys
rmax_dat <- as.matrix(rmax_dat[, -c(1:3, 20)])[, 16:1] # reorder exposures, remove keys
pr_dat <- as.matrix(pr_dat[, -c(1:3, 20)])[, 16:1] # reorder exposures, remove keys
##### 2. Restrict to complete follow-up 2009 through 2016, no deaths #####
idx <- which(rowSums(is.na(pm25_dat[, 1:10])) == 0 & # no missing exposures
rowSums(is.na(no2_dat[, 1:10])) == 0 &
rowSums(is.na(ozone_dat[, 1:10])) == 0 &
rowSums(is.na(tmmx_dat[, 1:10])) == 0 &
rowSums(is.na(rmax_dat[, 1:10])) == 0 &
rowSums(is.na(pr_dat[, 1:10])) == 0 &
qid_dat$entry == 2000) # follow up from 2000
qid_dat <- qid_dat[idx]
pm25_dat <- pm25_dat[idx,]
no2_dat <- no2_dat[idx,]
ozone_dat <- ozone_dat[idx,]
tmmx_dat <- tmmx_dat[idx,]
rmax_dat <- rmax_dat[idx,]
pr_dat <- pr_dat[idx,]
##### Data fixes #####
qid_dat[, age_corrected := entry_age + year - entry]
qid_dat[, PIR := medianhousevalue/medhouseholdincome]
# clear missing data, infinite PIR
idx2 <- which(complete.cases(qid_dat[,.(year, age_corrected, dual, race, sexM,
education, poverty, medianhousevalue,
medhouseholdincome, pct_blk, hispanic,
popdensity, pct_owner_occ, PIR)]) &
!is.infinite(qid_dat$PIR))
qid_dat <- qid_dat[idx2]
pm25_dat <- pm25_dat[idx2,]
no2_dat <- no2_dat[idx2,]
ozone_dat <- ozone_dat[idx2,]
tmmx_dat <- tmmx_dat[idx2,]
rmax_dat <- rmax_dat[idx2,]
pr_dat <- pr_dat[idx2,]
##### Remove QID after missing year of data #####
idx3 <- which(qid_dat$year == 2010)
qid_rm <- qid_dat[year == 2010, qid]
for (yr in 2011:2016) {
idx3 <- c(idx3, which(qid_dat$year == yr &
qid_dat$qid %in% qid_rm))
qid_rm <- qid_dat[idx3][year == yr, qid]
}
qid_dat <- qid_dat[idx3]
pm25_dat <- pm25_dat[idx3,]
no2_dat <- no2_dat[idx3,]
ozone_dat <- ozone_dat[idx3,]
tmmx_dat <- tmmx_dat[idx3,]
rmax_dat <- rmax_dat[idx3,]
setkey(qid_dat, year, zip, qid)
pr_dat <- pr_dat[idx3,]
rm(idx, idx2, idx3, qid_rm)
##### Summary stats #####
qid_dat[, .N]
##### 4. DLMM analysis - TDLMM #####
library(dlmtree)
library(mgcv)
prD_L <- bam(dead ~ factor(year) - 1 +
age_corrected + I(age_corrected^2) +
factor(dual) + factor(race) + factor(sexM) +
education + poverty +
I(medianhousevalue/medhouseholdincome) +
pct_blk + hispanic + popdensity + pct_owner_occ,
data = qid_dat,
family = binomial)
prD <- bam(dead ~ factor(year) - 1,
data = qid_dat,
family = binomial)
qid_dat[, pD := predict(prD, newdata = .SD, type = "response") /
predict(prD_L, newdata = .SD, type = "response")]
mm <- tdlmm(first_hosp ~ factor(year) - 1 + pD +
age_corrected + I(age_corrected^2) +
factor(dual) + factor(race) + factor(sexM) +
education + poverty +
I(medianhousevalue/medhouseholdincome) +
pct_blk + hispanic + popdensity + pct_owner_occ,
data = qid_dat,
exposure.data = list(pm25 = pm25_dat[,1:10],
no2 = no2_dat[,1:10],
ozone = ozone_dat[,1:10],
tmmx = tmmx_dat[,1:10],
rmax = rmax_dat[,1:10],
pr = pr_dat[,1:10]),
mixture.interactions = "noself",
family = "logit",
mix.prior = 0.167, # Prior inc prob = 0.5
n.trees = 20, n.burn = 5000, n.iter = 10000, n.thin = 5)
save(mm, file = paste0(dir_data, "analysis/tdlmm_state", state, "_", AD_ADRD, "_",
code_type, "_pm25_no2_ozone_tmmx_rmax_pr.rda"))
(ss <- summary(mm, conf.level = .95))
plot(ss)
